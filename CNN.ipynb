{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import cv2\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Load pre-trained VGG16 model with ImageNet weights\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "# Summary of the model architecture\n",
    "# model.summary()\n",
    "\n",
    "# Load and preprocess the image from a local file path\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)  # Read image from the local file path\n",
    "    if img is None:\n",
    "        raise Exception(f\"Unable to load image at path: {image_path}\")\n",
    "    \n",
    "    img = cv2.resize(img, (224, 224))  # Resize to 224x224\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    img = preprocess_input(img)  # Normalize for the CNN\n",
    "    return img\n",
    "\n",
    "# Function to describe the difference based on the distance\n",
    "def describe_difference(distance):\n",
    "    if distance < 100:\n",
    "        return \"The images are very similar, with almost no noticeable differences.\"\n",
    "    elif 100 <= distance < 500:\n",
    "        return \"The images have some noticeable differences, but they are still quite similar.\"\n",
    "    elif 500 <= distance < 1000:\n",
    "        return \"The images have several differences, and they appear moderately distinct from one another.\"\n",
    "    else:\n",
    "        return \"The images are very different, with significant changes in content or appearance.\"\n",
    "\n",
    "\n",
    "\n",
    "def cnn_process(image_path1, image_path2) :\n",
    "    \n",
    "  # Preprocess the images\n",
    "  image1 = preprocess_image(image_path1)\n",
    "  image2 = preprocess_image(image_path2)\n",
    "\n",
    "  # Extract features from the last convolutional layer\n",
    "  features1 = model.predict(image1)\n",
    "  features2 = model.predict(image2)\n",
    "\n",
    "  # Flatten the feature vectors\n",
    "  features1 = features1.flatten()\n",
    "  features2 = features2.flatten()\n",
    "\n",
    "  # Calculate Euclidean distance\n",
    "  distance = norm(features1 - features2)\n",
    "#   print(f'Euclidean Distance between the images: {distance}')\n",
    "  print(f\"{distance}\")\n",
    "  with open(\"output.txt\", \"a\") as file:\n",
    "    file.write(str(distance) + \"\\n\")  # Add a newline after each result\n",
    "\n",
    "  # Get a sentence describing the difference\n",
    "#   description = describe_difference(distance)\n",
    "#   print(description)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_process('./data/images/lectureimage/lectureex1.png', './data/images/lectureimage/lectureex2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_process('./data/images/lectureimage/lectureex1.png', './data/images/bunny.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_process('./data/images/lectureimage/lectureex1.png', './data/images/lectureimage/lectureex3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def extract_and_save_scenes(video_path, output_dir):\n",
    "    \"\"\"\n",
    "    Extracts one frame per second from the provided video, saves them as image files locally,\n",
    "    and returns scenes as a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    video_path (string): Path of the video to be processed.\n",
    "    output_dir (string): Directory where the extracted frames will be saved.\n",
    "\n",
    "    Returns:\n",
    "    list of dict: Each dictionary corresponds to a scene, containing:\n",
    "        - index (int): Scene index\n",
    "        - img_file (string): File name of the saved image\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"{video_path}: File not found.\")\n",
    "        return []\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    if fps <= 0:\n",
    "        print(f\"Error: Could not retrieve FPS from {video_path}\")\n",
    "        return []\n",
    "\n",
    "    scenes = []\n",
    "    index = 0\n",
    "    success, frame = cap.read()\n",
    "    count = 0\n",
    "\n",
    "    while success:\n",
    "        # Capture frame every second (approximately)\n",
    "        if count % int(fps) == 0:\n",
    "            # Convert the input image to gray scale\n",
    "            # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            # Define the file name for the saved image\n",
    "            img_file = os.path.join(output_dir, f\"scene_{index}.jpg\")\n",
    "            \n",
    "            # Save the frame as an image file\n",
    "            cv2.imwrite(img_file, frame)\n",
    "            \n",
    "            # Append scene info to the list\n",
    "            scenes.append({\n",
    "                \"index\": index,\n",
    "                \"img_file\": img_file\n",
    "            })\n",
    "            \n",
    "            index += 1\n",
    "        \n",
    "        success, frame = cap.read()\n",
    "        count += 1\n",
    "\n",
    "    cap.release()\n",
    "    \n",
    "    return scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def compare_scenes_in_reverse(scenes, cnn_process):\n",
    "    \"\"\"\n",
    "    Compares all scenes in reverse order using the cnn_process function.\n",
    "\n",
    "    Parameters:\n",
    "    scenes (list of dict): List of dictionaries where each dict contains:\n",
    "        - index (int): Scene index\n",
    "        - img_file (string): File name of the saved image\n",
    "    cnn_process (function): Function to compare two images.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Compare images in reverse order\n",
    "    for i in range(len(scenes) - 1, 0, -1):\n",
    "        image_path1 = scenes[i][\"img_file\"]\n",
    "        image_path2 = scenes[i - 1][\"img_file\"]\n",
    "        \n",
    "        # print(f\"Comparing Scene {scenes[i]['index']} and Scene {scenes[i-1]['index']}:\")\n",
    "        # print(f\"{scenes[i]['index']}-{scenes[i-1]['index']}:\")\n",
    "        cnn_process(image_path1, image_path2)\n",
    "        # print(\"-\" * 50)  # Separator for readability\n",
    "\n",
    "# Example Usage:\n",
    "# Assuming 'scenes' is the list returned by extract_and_save_scenes() function\n",
    "# and cnn_process() is the function to compare two images.\n",
    "# scenes = extract_and_save_scenes(\"path_to_video.mp4\", \"output_directory\")\n",
    "# compare_scenes_in_reverse(scenes, cnn_process)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"data/videos/test0_toy_lecture.mp4\"\n",
    "output_dir = \"out_directory0\"\n",
    "scenes = extract_and_save_scenes(video_path, output_dir)\n",
    "print(f\"Extracted and saved {len(scenes)} scenes.\")\n",
    "compare_scenes_in_reverse(scenes, cnn_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
